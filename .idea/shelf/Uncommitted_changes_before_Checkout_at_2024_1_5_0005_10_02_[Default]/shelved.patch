Index: crawlerTools/different_crawler/crawler_case/douban_crawler.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># 第一步使用urllib库获取网页\r\n# 第二步使用BeautifulSoup和re库解析数据:定位数据块、使用正则解析数据块\r\n# 将数据导出excel\r\nimport http.client\r\n\r\nimport requests\r\nimport urllib.request, urllib.error\r\nfrom bs4 import BeautifulSoup\r\nimport re\r\nimport xlwt\r\nfrom crawler_common_function import CrawlerCommonFunction\r\n\r\nclass DoubanCrawler(object):\r\n    # 定义基础url，发现规律，每页最后变动的是start=后面的数字\r\n    baseurl = \"https://movie.douban.com/top250?start=\"\r\n    # 定义正则对象获取指定的内容\r\n    # 提取链接（链接的格式都是<a href=\"开头的）\r\n    findLink = re.compile(r'<a href=\"(.*?)\">')\r\n    # 提取图片\r\n    findImgSrc = re.compile(r'<img.*src=\"(.*?)\"', re.S)  # re.S让 '.' 特殊字符匹配任何字符，包括换行符；\r\n    # 提取影片名称\r\n    findTitle = re.compile(r'<span class=\"title\">(.*)</span>')\r\n    # 提取影片评分\r\n    findRating = re.compile(r'<span class=\"rating_num\" property=\"v:average\">(.*)</span>')\r\n    # 提取评价人数\r\n    findJudge = re.compile(r'<span>(\\d*)人评价</span>')\r\n    # 提取简介\r\n    inq = re.compile(r'<span class=\"inq\">(.*)</span>')\r\n    # 提取相关内容\r\n    findBd = re.compile(r'<p class=\"\">(.*)</p>(.*)<div', re.S)\r\n\r\n\r\n\r\n    # 定义一个函数，并解析这个网页\r\n    def analysisDataDouBanTop250(self,baseurl):\r\n        # 定义接收10页的列表\r\n        dataList = []\r\n        # 获取指定网页\r\n        for i in range(0, 10):  # 获取网页选项的函数，10次\r\n            url = baseurl + str(i * 25)\r\n            html = CrawlerCommonFunction().getUrlContent(url,CrawlerCommonFunction().getUrlType[\"htmlType\"])\r\n            # 指定解析器解析html,得到BeautifulSoup对象\r\n            soup = BeautifulSoup(html)\r\n            # 定位我们的数据块在哪\r\n            for item in soup.find_all('div', class_=\"item\"):\r\n                # item 是 bs4.element.Tag 对象，这里将其转换成字符串来处理\r\n                item = str(item)\r\n                # 定义一个列表 来存储每一个电影解析的内容\r\n                data = []\r\n                # findall返回的是一个列表，这里提取链接\r\n                link = re.findall(self.findLink, item)[0]\r\n                data.append(link)  # 添加链接\r\n                img = re.findall(self.findImgSrc, item)[0]\r\n                data.append(img)  # 添加图片链接\r\n                title = re.findall(self.findTitle, item)\r\n                # 一般都有一个中文名 一个外文名\r\n                if len(title) == 2:\r\n                    # ['肖申克的救赎', '\\xa0/\\xa0The Shawshank Redemption']\r\n                    titlename = title[0] + title[1].replace(u'\\xa0', '')\r\n                else:\r\n                    titlename = title[0] + \"\"\r\n                data.append(titlename)  # 添加标题\r\n                pf = re.findall(self.findRating, item)[0]\r\n                data.append(pf)\r\n                pjrs = re.findall(self.findJudge, item)[0]\r\n                data.append(pjrs)\r\n                inqInfo = re.findall(self.inq, item)\r\n                if len(inqInfo) == 0:\r\n                    data.append(\" \")\r\n                else:\r\n                    data.append(inqInfo[0])\r\n                bd = re.findall(self.findBd, item)[0]\r\n                # [('\\n                            导演: 弗兰克·德拉邦特 Frank Darabont\\xa0\\xa0\\xa0主演: 蒂姆·罗宾斯 Tim Robbins /...<br/>\\n                            1994\\xa0/\\xa0美国\\xa0/\\xa0犯罪 剧情\\n                        ', '\\n\\n                        \\n                        ')]\r\n                bd[0].replace(u'\\xa0', '').replace('<br/>', '')\r\n                bd = re.sub('<\\\\s*b\\\\s*r\\\\s*/\\\\s*>', \"\", bd[0])\r\n                bd = re.sub('(\\\\s+)?', '', bd)\r\n                data.append(bd)\r\n                dataList.append(data)\r\n        return dataList\r\n\r\n\r\n\r\n    def doubanMainCrawler(self):\r\n        save_dataList=self.analysisDataDouBanTop250(self.baseurl)\r\n        save_path = \"E:\\\\Desktop\\\\ChenLiqingInterviewPrepare\\\\Coding\\\\brushQuestions\\\\crawlerTools\\\\download_file\\\\DouBan250_1.xls\"\r\n        igm_path= \"E:\\\\Desktop\\\\ChenLiqingInterviewPrepare\\\\Coding\\\\brushQuestions\\\\crawlerTools\\\\download_img\\\\\"\r\n        col_name = (\"电影详情链接\", \"图片链接\", \"电影中/外文名\", \"评分\", \"评论人数\", \"概况\", \"相关信息\")\r\n        sheet_name = \"豆瓣电影Top250\"\r\n        col_num=7\r\n        line_num=250\r\n        need_download_img=False\r\n        CrawlerCommonFunction().excelSave(sheet_name, col_name, col_num, line_num, save_path, save_dataList,need_download_img,igm_path)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    DoubanCrawler().doubanMainCrawler()
===================================================================
diff --git a/crawlerTools/different_crawler/crawler_case/douban_crawler.py b/crawlerTools/different_crawler/crawler_case/douban_crawler.py
--- a/crawlerTools/different_crawler/crawler_case/douban_crawler.py	
+++ b/crawlerTools/different_crawler/crawler_case/douban_crawler.py	
@@ -82,7 +82,8 @@
 
     def doubanMainCrawler(self):
         save_dataList=self.analysisDataDouBanTop250(self.baseurl)
-        save_path = "E:\\Desktop\\ChenLiqingInterviewPrepare\\Coding\\brushQuestions\\crawlerTools\\download_file\\DouBan250_1.xls"
+        save_path =""
+        # save_path = "E:\\Desktop\\ChenLiqingInterviewPrepare\\Coding\\brushQuestions\\crawlerTools\\download_file\\DouBan250_1.xls"
         igm_path= "E:\\Desktop\\ChenLiqingInterviewPrepare\\Coding\\brushQuestions\\crawlerTools\\download_img\\"
         col_name = ("电影详情链接", "图片链接", "电影中/外文名", "评分", "评论人数", "概况", "相关信息")
         sheet_name = "豆瓣电影Top250"
